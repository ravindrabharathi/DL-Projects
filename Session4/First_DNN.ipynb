{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravindrabharathi/Project1/blob/master/Session4/First_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBzDI9HEsAmu",
        "colab_type": "text"
      },
      "source": [
        "# Build a Convolutional Neural Network with less than 15000 parameters to achieve a validation accuracy of 99.4 or more for MNIST dataset \n",
        "\n",
        "\n",
        "The target is to build a deep learning CNN model with as little parameters as possible and at the same time achieve a high validation accuracy of 99.4 or more . The low parameter count becomes important when deploying the model in memory constrained devices used in edge computing . MNIST is one of the more popular (and simpler) datasets to begin your journey in Vision based Deep learning. We will use this MNIST dataset for this exercise. \n",
        "\n",
        "We will build the model step by step . Broadly speaking we will follow these steps \n",
        "\n",
        "1. Decide on the basic architecture for the network \n",
        "2. Fine tune parameters to comply with the 15000 limit\n",
        "3. Add improvements to the network using Batch Normalization \n",
        "4. See if we can converge faster while learning by using Dropouts to overcome overfitting ,higher   learning rates, etc \n",
        "\n",
        "In this notebook we will fix the Basic architecture that we think is suitable without bothering about number of parameters "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0uvqzIGp5zc",
        "colab_type": "text"
      },
      "source": [
        "###Import necessary libraries / modules\n",
        "Import numpy library for array/ matrix operations\n",
        "\n",
        "Import Sequential Model from keras/models for building the model\n",
        "\n",
        "Import Conv2D , Activation , Flatten , BatchNormalization, MaxPooling2D from keras/layers \n",
        "\n",
        "Import np_utils module from keras/utils for numpy related helper functions\n",
        "\n",
        "Import mnist dataset containing hand-written digits images from keras.datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "outputId": "26320de2-bb87-47db-a678-ba10da6f5321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "c8126a85-7927-458c-ac3a-f1e8a75bf294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db3hDvFDqpS9",
        "colab_type": "text"
      },
      "source": [
        "###print the shape of training data and also inspect the first image using matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "d21fa49e-b4c0-4fcc-d6a5-c56456cf9760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbe79592668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7BHSzLjq6nT",
        "colab_type": "text"
      },
      "source": [
        "####Reshape the training and test dataset to include the channel information.In this case it is a greyscale image and so there is 1 channel . the image data was read in as a 28x28 numpy array and is now reshaped to 28x28x1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3aPHupgrF5a",
        "colab_type": "text"
      },
      "source": [
        "###Cast training data as float32 and normalize/re-scale the values such that they are between 0 and 1 instead of 0 and 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmUE1nCXrMua",
        "colab_type": "text"
      },
      "source": [
        "###inspect the first 10 training class labels . They will be some number between 0 and 9 representing the hand-written digit in the corresponding Training data. Each of 0 to 9 represents a class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "9468663b-7c47-4f35-9667-f522e3a1275c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dld_th_rU9s",
        "colab_type": "text"
      },
      "source": [
        "####One hot encoding of training and test class labels : Convert 1-dimensional class arrays to 10-dimensional class matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "c9f20d8a-67a6-4e8c-f32d-13ea1410e0ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNM1NgZdtQm8",
        "colab_type": "text"
      },
      "source": [
        "###Define a ModelCheckPoint callback which will be called at the end of every training epoch . We will use this callback function to save the model whenever vallidation accuracy improves . We do this so that we can load and use the best model for further predictions after training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yr6tsrzcSce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "  \n",
        "#chkpoint_model=ModelCheckpoint(\"/gdrive/My Drive/EVA/Session3/model_customv1_mnist_best.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='max') \n",
        "\n",
        "chkpoint_model=ModelCheckpoint(\"model_custom_v1_mnist_best.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='max') \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmyGmS8oy2qE",
        "colab_type": "text"
      },
      "source": [
        "#Building the model version 1\n",
        "\n",
        "In version 1 of the model we will try and get the basic architecture correct. We will focus on adding the proper convolution layers that gives a good enough accuracy to start with . We will not bother about the parameter constraints at this point.\n",
        "\n",
        "In our architecture for every convolution block we start from a small number and increase the number of filters for every additional layer in the block . Typically for a 400x400 image we would go upto a receptive field of 11x11 starting from 32 kernels increasing to 512 kernels such that the network learns enough about edges, gradients ,textures, patterns, parts of object , object and scene in each progressive block . In our case the images are small and relative much simpler and so we will use lesser number of blocks and also lesser layers within each block.\n",
        "\n",
        "Considering the size of the image (28x28) and the relative simple nature of the classes (digits 0-9) to be classified, we will add only two convolution blocks containing 3x3 filters until we get to a channel size of  7x7 .  At the point where the channel size is 7X7 , we will add a convolution block of 10 filters of size 7x7 which feeds into a flatten layer followed by softmax activation . Between these two convolution blocks we will have a transition block of 1x1 convolution and maxpooling .\n",
        "\n",
        "We will not add convolution layers after the channel size has reached 7x7 . This is because when a 3x3 filter convolves over an image of size 5x5 it sees the pixels a disproportionate number of times as seen below and convovling further doesn't retain enough spatial information   \n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ravindrabharathi/eip3/master/images/pixels-55.png\" alt=\"drawing\" width=\"300\"/> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <img src=\"https://raw.githubusercontent.com/ravindrabharathi/eip3/master/images/pixels-77.png\" alt=\"drawing\" width=\"300\"/>\n",
        "\n",
        "All these convolution layers will use ReLU activation function . Using an activation function introduces non-linearity in the network allowing them to learn complex functions .Without these non-linear activation functions the network will only be a stack of linear functions . ReLU activation is one of the simplest and most popular activations used in CNN . It essentially suppresses -ve values from moving forward giving the network a simple rule for retaining or discarding features that it is learning - work towards making values positive if you want something retained and make the values negative if you want to drop something. \n",
        "\n",
        "First convolution layer :\n",
        "\n",
        "The first convolution layer will have 32 3x3 kernels \n",
        "\n",
        "First Convolution Block :\n",
        "\n",
        "The first block allows the network to learn edges and gradients. This block will have 2 layers of convolution filters of size 3x3 . The number of kernels in the first layer is 64 (increses from 32 used in the first convolution layer ) and the second layer has 128 kernels . With a global receptive field of 7x7 , the network should be able to learn enough about edges and gradients . \n",
        "\n",
        "Transition Block : \n",
        "since we want to start the next convolution block at a smaller number of kernels , we will use a 1x1 convolution layer to reduce the number of channels after the first convolution block . 1x1 kernel convolution is an effective  way of combining a large number of channels to form a set of smaller number of channels. \n",
        "We will also spatially downsample the channels by using maxpooling of size 2x2. Maxpooling of size 2x2 will reduce the channel size by half while doubling the global receptive field \n",
        "\n",
        "Second convolution block : \n",
        "\n",
        "The second block will allow the network to form the important parts that make up the digits . This will contain two layers of 3x3 kernels . Firts layer will have 64 kernels and the second will have 128 kernels . \n",
        "\n",
        "1x1 convolution to transition to 10 channels :\n",
        "\n",
        "After the second convolution block we add a convolution layer of 10 1x1 kernels .  Since we have only 10 classes , we will combine the 16 channels from earlier layers to form 10 channels .\n",
        "\n",
        "Last Layer : 7x7 kernel \n",
        "\n",
        "Since we stopped our second convolution block at an activation size of 7x7 , we will add a convolution layer of 10 numbers of 7x7 kernels as the last layer in order to send a 1x1x10 output to the Flatten layer .\n",
        "It is important not to have ReLU activation for this 1x1 layer since we want all values from the convolution to go to the Softmax activation to make its prediction . If we use a ReLu activation , the -ve values will be suppressed and the network will be unable to train in an optimal manner.\n",
        "\n",
        "Flatten: \n",
        "\n",
        "These 10 channel outputs are fed to a Flatten layer that converts the 2d array representation to a 1d shape . \n",
        "\n",
        "Softmax activation: \n",
        "\n",
        "A softmax activation layer at the end outputs the class probabilities of these 10 classes which in our case are the digits 0 to 9 . \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdn9MvWmVOtA",
        "colab_type": "code",
        "outputId": "e049721b-5070-4880-a10d-bac5b5bd6692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# to get a certain degeree of predictability when generating random numbers,\n",
        "# set a random seed to initialize the pseudo-random number generator \n",
        "np.random.seed(seed=42)  \n",
        "\n",
        "# instantiate a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# add the first convolution layer - 32 numbers of 3x3 filters , \n",
        "#This layer sees the input image of 28x28 x 1 channel . \n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1), use_bias=False))  # remove bias param by setting it to false \n",
        "  \n",
        "model.add(Activation('relu'))    # use ReLU activation function .\n",
        "\n",
        "# Now the global receptive field is 3 x 3 \n",
        "\n",
        "# First Convolution Block\n",
        "# Block1 conv layer 1 - 64 filters of shape  3x3x32 \n",
        "# input from previous layer is 26 x 26 x 32 . \n",
        "\n",
        "## Block 1\n",
        "\n",
        "model.add(Conv2D(64, 3, use_bias=False))  # remove bias param by setting it to false \n",
        " \n",
        "model.add(Activation('relu'))    # use ReLU activation function .\n",
        "\n",
        "#Global receptive field is 5x5\n",
        "\n",
        "# Add convolution layer - 128 filters of shape  3x3x64 \n",
        "#input from previous layer is 24 x 24 x 64 . \n",
        "\n",
        "model.add(Conv2D(128, 3, use_bias=False))  # remove bias param by setting it to false \n",
        " \n",
        "model.add(Activation('relu'))    # use ReLU activation function .\n",
        "\n",
        "\n",
        "#Global receptive field is 7x7\n",
        "\n",
        "##  Transition block \n",
        "\n",
        "# Perform 2x2 max pooling  . \n",
        "#Input from previous layer is 22 x 22 X 128 \n",
        "\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "# After max pooling , 2D spatial dimension reduces by half , i.e it becomes 11 x 11 . \n",
        "# Maxpooling (withpool size 2 and stride 1) doubles receptive field . \n",
        "# So global receptive field after max pooling is 14 x 14\n",
        "\n",
        "# add 1x1 convolution to reduce the channel numbers to 32 \n",
        "\n",
        "model.add(Conv2D(32, 1, use_bias=False))  # remove bias param by setting it to false \n",
        " \n",
        "model.add(Activation('relu'))    # use ReLU activation function .\n",
        "\n",
        "\n",
        "#Convolution Block 2\n",
        "\n",
        "# Add convolution layer - 64 filters of shape 3x3x32\n",
        "#input from transition layer is 11 x 11 x 32 .  \n",
        "\n",
        "model.add(Conv2D(64, 3,  use_bias=False))  # remove bias param by setting it to false \n",
        "\n",
        "model.add(Activation('relu'))    # use ReLU activation function .\n",
        "\n",
        "#Global receptive field is now 16 x 16 \n",
        "\n",
        "# Add convolution layer - 16 filters of shape 3x3x16 \n",
        "#input coming from previous layer is 9 x 9 x 64 . \n",
        "\n",
        "model.add(Conv2D(128, 3,  use_bias=False)) # remove bias param by setting it to false \n",
        " \n",
        "model.add(Activation('relu'))    # use ReLU activation function .\n",
        "\n",
        "#  Global receptive field is now 18 x 18 \n",
        "\n",
        "# Add 1x1 convolution to reduce number of channels to 10  \n",
        "#input coming from previous layer is 7 x 7 x 128 .\n",
        "\n",
        "model.add(Conv2D(10, 1,  use_bias=False))  # remove bias param by setting it to false \n",
        " \n",
        "model.add(Activation('relu'))    # use ReLU activation function .\n",
        "\n",
        "#Global receptive field is now 18 x 18 \n",
        "\n",
        "# Last layer :  Add convolution layer - 10 filters of shape 7x7x10 \n",
        "#input coming from previous layer is 7 x 7 x 10 .\n",
        "\n",
        "model.add(Conv2D(10, 7,  use_bias=False))  # remove bias param by setting it to false \n",
        "\n",
        "# Note absence of ReLU activation here \n",
        "\n",
        "model.add(Flatten())  # Flatten the 2d array to 1d input for the softmax activation \n",
        "model.add(Activation('softmax'))   # Softmax activation to out class probabilities "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTdVH726xhN3",
        "colab_type": "code",
        "outputId": "83068c9b-c6c3-4b86-adf0-bab4477cff8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        288       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18432     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 128)       73728     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 22, 22, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 32)        4096      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 64)          18432     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 128)         73728     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 10)          1280      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          4900      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 194,884\n",
            "Trainable params: 194,884\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7A0AhG_xrjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqappyT1x7sf",
        "colab_type": "code",
        "outputId": "76e9bbe0-72be-43b3-d726-ed82f33c5e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "model.fit(X_train, Y_train, validation_data=(X_test,Y_test),batch_size=32, epochs=10, verbose=1, callbacks=[chkpoint_model])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 17s 291us/step - loss: 0.1489 - acc: 0.9546 - val_loss: 0.0575 - val_acc: 0.9817\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.98170, saving model to model_custom_v1_mnist_best.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0533 - acc: 0.9838 - val_loss: 0.0398 - val_acc: 0.9865\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.98170 to 0.98650, saving model to model_custom_v1_mnist_best.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 13s 216us/step - loss: 0.0413 - acc: 0.9875 - val_loss: 0.0528 - val_acc: 0.9834\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.98650\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 13s 224us/step - loss: 0.0321 - acc: 0.9902 - val_loss: 0.0347 - val_acc: 0.9887\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.98650 to 0.98870, saving model to model_custom_v1_mnist_best.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0260 - acc: 0.9921 - val_loss: 0.0288 - val_acc: 0.9912\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.98870 to 0.99120, saving model to model_custom_v1_mnist_best.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.0214 - acc: 0.9934 - val_loss: 0.0272 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.99120 to 0.99220, saving model to model_custom_v1_mnist_best.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0187 - acc: 0.9939 - val_loss: 0.0417 - val_acc: 0.9865\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.99220\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0160 - acc: 0.9950 - val_loss: 0.0301 - val_acc: 0.9915\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.99220\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0128 - acc: 0.9957 - val_loss: 0.0349 - val_acc: 0.9915\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.99220\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 14s 226us/step - loss: 0.0124 - acc: 0.9960 - val_loss: 0.0353 - val_acc: 0.9900\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbe765b6940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAo7lmRA0FIE",
        "colab_type": "text"
      },
      "source": [
        "**We trained the model for 10 epochs and it has a max validation accuracy of 99.22 . The number of parameters is a concern as it is far more (195k) than the 15k limit. We will attend to number of parameters in the next iteration** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7fa3y3MszKQ",
        "colab_type": "text"
      },
      "source": [
        "### Let us load the Model with best validation accuracy and print the evaluation score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvdXCXK2l9KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=load_model(\"model_custom_v1_mnist_best.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "051a39d5-d394-489e-fd99-f584c77b99fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.027160424402708303, 0.9922]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Acfgy31CtWYc",
        "colab_type": "text"
      },
      "source": [
        "### Predict the classes using model.predict and print predicted probabilities and categorical array for True test classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "8f86fe0d-98a8-4335-ca9a-16f85ceeca8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(Y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.85907703e-11 5.66314808e-11 1.21949469e-07 2.49639157e-07\n",
            "  4.83767323e-13 2.21865348e-09 2.20653892e-19 9.99999642e-01\n",
            "  5.30516013e-11 5.13741361e-09]\n",
            " [1.76808371e-07 5.42926628e-08 9.99997497e-01 8.02094610e-13\n",
            "  1.20663002e-11 1.22894045e-13 2.25636290e-06 4.47469083e-15\n",
            "  3.61097374e-10 1.13210614e-08]\n",
            " [1.41675017e-07 9.99997735e-01 1.22548016e-07 1.52157665e-13\n",
            "  1.46854134e-07 4.00673592e-08 9.40787337e-10 1.84047894e-06\n",
            "  6.28399111e-10 2.96663777e-10]\n",
            " [9.99928355e-01 1.25329347e-09 8.09112635e-07 1.70795633e-09\n",
            "  2.11708198e-08 4.02868068e-08 5.72565341e-06 2.14720792e-08\n",
            "  8.70664508e-07 6.40705111e-05]\n",
            " [9.97566699e-12 4.99897956e-10 1.91461864e-11 1.42243566e-15\n",
            "  9.99995589e-01 6.22501291e-13 2.78738554e-07 9.85402352e-14\n",
            "  7.76119435e-08 4.13036832e-06]\n",
            " [4.84416507e-09 9.99999762e-01 2.32947190e-08 2.57915010e-15\n",
            "  1.32189982e-07 1.47773926e-09 2.45609200e-10 1.12783546e-07\n",
            "  1.51514981e-10 5.42994330e-11]\n",
            " [4.00141441e-17 8.40407188e-11 1.80260565e-13 4.62699275e-18\n",
            "  9.99998808e-01 7.59180566e-12 1.79237339e-15 3.53361632e-12\n",
            "  1.18250102e-06 6.03930150e-09]\n",
            " [8.75259153e-12 1.55813612e-10 6.10468831e-09 1.15274424e-12\n",
            "  8.87624119e-05 2.13073531e-10 1.78293459e-12 2.92014191e-09\n",
            "  2.31005757e-07 9.99910951e-01]\n",
            " [1.80020461e-08 1.65073660e-14 3.63872127e-11 3.06936448e-10\n",
            "  5.94404951e-12 9.90337133e-01 8.83710943e-03 2.83217562e-14\n",
            "  8.25078576e-04 7.18206479e-07]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYPrkzLvt2do",
        "colab_type": "text"
      },
      "source": [
        "### Let us visualize some of the filters in the first convolution layer 'conv2d_1'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# form a layer dictionary {name : layer} of all layers in the model \n",
        "\n",
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "outputId": "d3315864-f318-45f6-949c-cd6d376313ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        }
      },
      "source": [
        " # use matplotlib to visualize the filter arrays \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_1'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    elif layer_output.shape[3] >= 8:\n",
        "        plot_x, plot_y = 2, 4   \n",
        "    else:\n",
        "        \n",
        "        plot_x, plot_y = 2, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    \n",
        "    ax[0,0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0,0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x,y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x,y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwoAAAM0CAYAAAAbSNX8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJKvj/tnxxJtZJBYYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x864 with 24 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q6fJ67qvlsY",
        "colab_type": "text"
      },
      "source": [
        "### We built the first iteration of the model with 195k parameters and achieved a max validation accuracy of 99.22 within 10 epochs . This iteration was to fix the basic architecture of the network \n",
        "\n",
        "###We will improve this model in the next iteration "
      ]
    }
  ]
}