{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Crop_images_PersonAttributes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravindrabharathi/Project1/blob/master/EIP4/session5/Crop_images_PersonAttributes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9_ujcJ5y8nB",
        "colab_type": "text"
      },
      "source": [
        "# Code to crop away black pixels used to pad the person database images "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2o8K90OzPFj",
        "colab_type": "text"
      },
      "source": [
        "Mount google drive and copy project data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "outputId": "7a3744c9-82ce-422c-d1d0-b527825ae8eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "project_folder=\"/content/gdrive/My Drive/EIP4/session5\"\n",
        "\n",
        "!rm -R ./resized\n",
        "!rm hvc_annotations.csv\n",
        "!unzip -q \"/content/gdrive/My Drive/EIP4/session5/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "rm: cannot remove './resized': No such file or directory\n",
            "rm: cannot remove 'hvc_annotations.csv': No such file or directory\n",
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  hvc_annotations.csv  \u001b[01;34mresized\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WLRV5b3zWnj",
        "colab_type": "text"
      },
      "source": [
        "Load necessary libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "outputId": "93e653f5-10cd-44b6-e3ad-48fced39d3c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "from keras.applications import VGG16,ResNet50V2\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input,Conv2D,GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "np.random.seed(seed=2019)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uif7R4C_zapY",
        "colab_type": "text"
      },
      "source": [
        "Function to drop black padding pixels from images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aWiFS8anXMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from https://codereview.stackexchange.com/questions/132914/crop-black-border-of-image-using-numpy\n",
        "def crop_image(img,tol=0):\n",
        "  # img is 2D image data\n",
        "  # tol  is tolerance\n",
        "  channels=[]\n",
        "  min_width=224\n",
        "  min_height=224\n",
        "  for i in range(3):\n",
        "    img1=img[:,:,i]\n",
        "    #print(img1.shape)\n",
        "    mask = img1>tol\n",
        "    img2=img1[np.ix_(mask.any(1),mask.any(0))]\n",
        "    if img2.shape[1]<min_width:\n",
        "      min_width=img2.shape[1]\n",
        "    if img2.shape[0]<min_height:\n",
        "      min_height=img2.shape[0]  \n",
        "    channels.append(img2)\n",
        "    #print(img2.shape,min_width)\n",
        "    #print(min_width)\n",
        "  #\n",
        "    #print(type(channels[i]))\n",
        "  for i in range(3):\n",
        "    img4=channels[i]\n",
        "    img4=img4[0:min_height,0:min_width]\n",
        "    channels[i]=img4\n",
        "  img3=np.stack([channels[0], channels[1], channels[2]],axis=-1)\n",
        "  #print(img3.shape)\n",
        "  return img3 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csiCwVd5zk2o",
        "colab_type": "text"
      },
      "source": [
        "Process all images in person database "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dwIqvVRpznA",
        "colab_type": "code",
        "outputId": "4235e12c-3a04-4ebc-cf7b-ef09d38cb193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "import os\n",
        "!rm -R './cropped/'\n",
        "!mkdir './cropped'\n",
        "print('created cropped dir...')\n",
        "image_list=os.listdir('./resized/')\n",
        "print('starting image cropping ...')\n",
        "for i in range(len(image_list)):\n",
        "  #print('./resized/'+image_list[i])\n",
        "  image=cv2.imread('./resized/'+image_list[i])\n",
        "  #cv2_imshow(image)\n",
        "  image1=crop_image(image,tol=10)\n",
        "  cv2.imwrite('./cropped/'+image_list[i],image1)\n",
        "  if (i%1000==0):\n",
        "    print('processed ',i,'images')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created cropped dir...\n",
            "starting image cropping ...\n",
            "processed  0 images\n",
            "processed  1000 images\n",
            "processed  2000 images\n",
            "processed  3000 images\n",
            "processed  4000 images\n",
            "processed  5000 images\n",
            "processed  6000 images\n",
            "processed  7000 images\n",
            "processed  8000 images\n",
            "processed  9000 images\n",
            "processed  10000 images\n",
            "processed  11000 images\n",
            "processed  12000 images\n",
            "processed  13000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuKshXP8zsc9",
        "colab_type": "text"
      },
      "source": [
        "Archive(tar) the resulting images and copy them as cropped.tar to the google drive project directory "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naIT9bwaKAUt",
        "colab_type": "code",
        "outputId": "f80fa8ca-8bc1-447d-c760-941a37c425d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "image_list2=os.listdir('./cropped/')\n",
        "print(len(image_list),len(image_list2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13573 13573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l9ogmWuK6ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -cvf cropped.tar './cropped/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEeyFRxKLth9",
        "colab_type": "code",
        "outputId": "a35a5135-afdb-428f-af22-30c6992fbd00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!echo $project_folder"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/EIP4/session5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuxNEJtaLPc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp './cropped.tar' '$project_folder'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CExzBB37z9RF",
        "colab_type": "text"
      },
      "source": [
        "### Now that we have copied the cropped images to our project directory , we can use this dataset to train the model for multi output classification of age ,gender ,pose , weight , etc"
      ]
    }
  ]
}